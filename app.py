import streamlit as st
import pandas as pd
import json
import csv
from io import StringIO, BytesIO
from datetime import datetime
from preprocessing import VietnamesePreprocessor
from phobert_module import PhoBERTModule
from rule_based import RuleBasedSentiment
from fusion import ConditionalFusion
from db_connector import DBConnector

# Input validation functions
def validate_input(text):
    """
    Validate user input for spam, meaningless content, and length.
    Returns (is_valid, error_message)
    """
    if not text or text.strip() == "":
        return False, "‚ùå Vui l√≤ng nh·∫≠p vƒÉn b·∫£n!"

    text = text.strip()

    # Check minimum length
    if len(text) < 2:
        return False, "‚ùå VƒÉn b·∫£n qu√° ng·∫Øn! Vui l√≤ng nh·∫≠p √≠t nh·∫•t 2 k√Ω t·ª±."

    # Check maximum reasonable length (Vietnamese sentences)
    if len(text) > 1000:
        return False, "‚ö†Ô∏è VƒÉn b·∫£n qu√° d√†i! Gi·ªõi h·∫°n 1000 k√Ω t·ª±."

    # Check for spam/random characters
    import re

    # Count alphanumeric characters vs total
    alpha_count = len(re.findall(r'[a-zA-Z√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥\s]', text))
    total_chars = len(text)
    meaningful_ratio = alpha_count / total_chars if total_chars > 0 else 0

    # Check for excessive special characters/numbers
    if meaningful_ratio < 0.3:  # Less than 30% meaningful characters
        return False, "‚ùå VƒÉn b·∫£n c√≥ qu√° nhi·ªÅu k√Ω t·ª± ƒë·∫∑c bi·ªát ho·∫∑c s·ªë! Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát c√≥ nghƒ©a."

    # Check for keyboard mashing (repeated characters)
    if re.search(r'(.)\1{4,}', text):  # 5+ repeated characters
        return False, "‚ùå Ph√°t hi·ªán k√Ω t·ª± l·∫∑p l·∫°i! Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c√≥ nghƒ©a."

    # Check for excessive consecutive consonants (likely spam)
    consonants = 'bcdfghjklmnpqrstvwxyzƒë'
    max_consonant_streak = max(len(match) for match in re.findall(f'[{consonants}]+', text.lower()))
    if max_consonant_streak > 8:
        return False, "‚ùå VƒÉn b·∫£n c√≥ v·∫ª nh∆∞ spam! Vui l√≤ng nh·∫≠p c√¢u ti·∫øng Vi·ªát c√≥ nghƒ©a."

    # Additional spam detection: random keyboard patterns
    keyboard_patterns = [
        r'qwer', r'asdf', r'zxcv', r'1234', r'qwerty', r'asdfgh', r'zxcvbnm',
        r'qaz', r'wsx', r'edc', r'rfv', r'tgb', r'yhn', r'ujm', r'ik,', r'ol.',
        r'p;/', r'[\[\]{}|\\:;"<>?]', r'[=-_+`~]'
    ]
    text_lower = text.lower()
    spam_score = 0
    for pattern in keyboard_patterns:
        if re.search(pattern, text_lower):
            spam_score += 1

    # If multiple keyboard patterns detected, likely spam
    if spam_score >= 3:
        return False, "‚ùå Ph√°t hi·ªán pattern b√†n ph√≠m spam! Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c√≥ nghƒ©a."

    # Check for single word sentences that are too short
    words = text.split()
    if len(words) == 1 and len(text) < 3:
        return False, "‚ùå T·ª´ ƒë∆°n qu√° ng·∫Øn! Vui l√≤ng nh·∫≠p c√¢u c√≥ nghƒ©a."

    # Check for Vietnamese content (basic check)
    vietnamese_chars = '√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥'
    has_vietnamese = any(char in text for char in vietnamese_chars)

    if not has_vietnamese and len(text) > 10:
        return False, "‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán k√Ω t·ª± ti·∫øng Vi·ªát. Vui l√≤ng nh·∫≠p vƒÉn b·∫£n b·∫±ng ti·∫øng Vi·ªát."

    return True, ""

# Export functions
def export_to_csv(df):
    """Export dataframe to CSV"""
    csv_buffer = StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    return csv_buffer.getvalue()

def export_to_json(df):
    """Export dataframe to JSON"""
    # Convert timestamp to string for JSON serialization
    df_copy = df.copy()
    df_copy['Timestamp'] = df_copy['Timestamp'].astype(str)
    return json.dumps(df_copy.to_dict('records'), ensure_ascii=False, indent=2)

def export_to_html(df):
    """Export dataframe to HTML (for PDF-like display)"""
    html = f"""
    <html>
    <head>
        <meta charset="utf-8">
        <title>L·ªãch s·ª≠ Ph√¢n lo·∫°i C·∫£m x√∫c</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            h1 {{ color: #1f77b4; }}
            table {{ border-collapse: collapse; width: 100%; margin-top: 20px; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            tr:nth-child(even) {{ background-color: #f9f9f9; }}
        </style>
    </head>
    <body>
        <h1>L·ªãch s·ª≠ Ph√¢n lo·∫°i C·∫£m x√∫c</h1>
        <p>Xu·∫•t ng√†y: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        {df.to_html(index=False, classes='table table-striped')}
    </body>
    </html>
    """
    return html

def export_to_ics(df):
    """Export dataframe to ICS format (simplified calendar format)"""
    ics_content = "BEGIN:VCALENDAR\nVERSION:2.0\nPRODID:-//Sentiment Analysis//History//EN\n"
    
    for _, row in df.iterrows():
        ics_content += "BEGIN:VEVENT\n"
        ics_content += f"SUMMARY:Ph√¢n lo·∫°i - {row['Label']}\n"
        ics_content += f"DESCRIPTION:{row['Input'][:100]}...\n"
        # Convert timestamp to ICS format
        if isinstance(row['Timestamp'], str):
            dt = datetime.fromisoformat(row['Timestamp'].replace('Z', '+00:00'))
        else:
            dt = row['Timestamp']
        ics_content += f"DTSTART:{dt.strftime('%Y%m%dT%H%M%S')}\n"
        ics_content += f"DTEND:{(dt.replace(second=dt.second+1)).strftime('%Y%m%dT%H%M%S')}\n"
        ics_content += "END:VEVENT\n"
    
    ics_content += "END:VCALENDAR\n"
    return ics_content

def import_from_csv(uploaded_file):
    """Import data from CSV file"""
    try:
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        return df, None
    except Exception as e:
        return None, str(e)

def import_from_json(uploaded_file):
    """Import data from JSON file"""
    try:
        data = json.load(uploaded_file)
        df = pd.DataFrame(data)
        return df, None
    except Exception as e:
        return None, str(e)

# Cache resources
@st.cache_resource
def load_models():
    preprocessor = VietnamesePreprocessor()
    phobert = PhoBERTModule()
    rule_based = RuleBasedSentiment()
    fusion = ConditionalFusion()
    return preprocessor, phobert, rule_based, fusion

preprocessor, phobert, rule_based, fusion = load_models()
db = DBConnector()

st.title("Ph√¢n lo·∫°i c·∫£m x√∫c ti·∫øng Vi·ªát")

tab1, tab2 = st.tabs(["Ph√¢n lo·∫°i C·∫£m x√∫c", "L·ªãch s·ª≠ Ph√¢n lo·∫°i"])

with tab1:
    st.header("Ph√¢n lo·∫°i C·∫£m x√∫c")
    text_input = st.text_area("Nh·∫≠p c√¢u ti·∫øng Vi·ªát:", height=100)

    if st.button("Ph√¢n lo·∫°i"):
        if text_input.strip():
            # Validate input first
            is_valid, error_msg = validate_input(text_input)
            if not is_valid:
                st.error(error_msg)
            else:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # Preprocess
                    processed_text = preprocessor.preprocess(text_input)

                    # PhoBERT
                    l_phobert, c_phobert = phobert.analyze_sentiment(processed_text)

                    # Rule-based
                    s_rule = rule_based.analyze_sentiment(processed_text)

                    # Fusion
                    final_label, final_conf = fusion.fuse(l_phobert, c_phobert, s_rule)

                    # Display results
                    st.success(f"C·∫£m x√∫c: {final_label}")
                    st.info(f"ƒê·ªô tin c·∫≠y t·ªïng h·ª£p: {final_conf:.2f}")

                    # Save to DB
                    db.insert_history(text_input, processed_text, final_label, final_conf)
        else:
            st.error("‚ùå Vui l√≤ng nh·∫≠p vƒÉn b·∫£n!")

with tab2:
    st.header("L·ªãch s·ª≠ Ph√¢n lo·∫°i")
    history = db.fetch_history()
    if history:
        import pandas as pd
        df = pd.DataFrame(history, columns=["ID", "Input", "Processed", "Label", "Confidence", "Timestamp"])
        
        # Delete all button
        if st.button("X√≥a T·∫•t C·∫£ L·ªãch S·ª≠"):
            try:
                db.delete_all()
                st.success("ƒê√£ x√≥a t·∫•t c·∫£ l·ªãch s·ª≠! Vui l√≤ng l√†m m·ªõi trang.")
            except Exception as e:
                st.error(f"L·ªói khi x√≥a: {e}")
        
        # Multiselect for individual deletions
        selected_ids = st.multiselect("Ch·ªçn ID ƒë·ªÉ x√≥a:", df["ID"].tolist())
        if st.button("X√≥a C√°c ID ƒê√£ Ch·ªçn") and selected_ids:
            try:
                for id in selected_ids:
                    db.delete_by_id(id)
                st.success(f"ƒê√£ x√≥a {len(selected_ids)} b·∫£n ghi! Vui l√≤ng l√†m m·ªõi trang.")
            except Exception as e:
                st.error(f"L·ªói khi x√≥a: {e}")
        
        st.dataframe(df)
        
        # Export section
        st.subheader("Xu·∫•t d·ªØ li·ªáu")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            csv_data = export_to_csv(df)
            st.download_button(
                label="üìÑ Xu·∫•t CSV",
                data=csv_data,
                file_name=f"sentiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                key="csv_export"
            )
        
        with col2:
            json_data = export_to_json(df)
            st.download_button(
                label="üìã Xu·∫•t JSON",
                data=json_data,
                file_name=f"sentiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                key="json_export"
            )
        
        with col3:
            html_data = export_to_html(df)
            st.download_button(
                label="üìï Xu·∫•t HTML",
                data=html_data,
                file_name=f"sentiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html",
                key="html_export"
            )
        
        with col4:
            ics_data = export_to_ics(df)
            st.download_button(
                label="üìÖ Xu·∫•t ICS",
                data=ics_data,
                file_name=f"sentiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.ics",
                mime="text/calendar",
                key="ics_export"
            )
        
        # Import section
        st.subheader("Nh·∫≠p d·ªØ li·ªáu")
        uploaded_file = st.file_uploader("Ch·ªçn file CSV ho·∫∑c JSON ƒë·ªÉ nh·∫≠p", type=['csv', 'json'])
        
        if uploaded_file is not None:
            if uploaded_file.name.endswith('.csv'):
                import_df, error = import_from_csv(uploaded_file)
            elif uploaded_file.name.endswith('.json'):
                import_df, error = import_from_json(uploaded_file)
            else:
                st.error("Ch·ªâ h·ªó tr·ª£ file CSV v√† JSON!")
                import_df = None
            
            if import_df is not None:
                st.success(f"ƒê√£ ƒë·ªçc th√†nh c√¥ng {len(import_df)} b·∫£n ghi t·ª´ file.")
                st.dataframe(import_df.head())
                
                if st.button("Th√™m v√†o c∆° s·ªü d·ªØ li·ªáu"):
                    try:
                        imported_count = 0
                        for _, row in import_df.iterrows():
                            # Assuming columns: Input, Processed, Label, Confidence
                            if 'Input' in row and 'Label' in row:
                                processed = row.get('Processed', row['Input'])
                                confidence = row.get('Confidence', 0.5)
                                
                                # Insert into database (timestamp will be auto-generated)
                                db.insert_history(row['Input'], processed, row['Label'], confidence)
                                imported_count += 1
                        
                        st.success(f"ƒê√£ th√™m th√†nh c√¥ng {imported_count} b·∫£n ghi v√†o c∆° s·ªü d·ªØ li·ªáu!")
                        st.info("Vui l√≤ng l√†m m·ªõi trang ƒë·ªÉ xem d·ªØ li·ªáu m·ªõi.")
                    except Exception as e:
                        st.error(f"L·ªói khi th√™m d·ªØ li·ªáu: {e}")
            elif error:
                st.error(f"L·ªói khi ƒë·ªçc file: {error}")
        
    else:
        st.write("Ch∆∞a c√≥ l·ªãch s·ª≠.")